# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18_91vl4aaQXqU5X8F13S3Q5GYcJ5cNNt
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pandas_datareader import data as pdr
import yfinance as yf
import os

yf.pdr_override()
y_symbols = ['APOLLOHOSP.NS']
from datetime import datetime
startdate = datetime(2005,1,1)
enddate = datetime(2019,12,31)
data = pdr.get_data_yahoo(y_symbols, start=startdate, end=enddate)

data

data.tail()

data=data.reset_index()
data.head()

data=data.drop(['Date', 'Adj Close','Volume'],axis=1)
data.head()

plt.figure(figsize=(8,3))
plt.xlabel('Days')
plt.ylabel('Closing Price USD ($)')
plt.plot(data['Close'],'#840000')
plt.show()

data.Close

data.shape

#spliting data into training and testing

data_training = pd.DataFrame(data['Close'][0:int(len(data)*0.70)])
data_testing = pd.DataFrame(data['Close'][int(len(data)*0.70): int(len(data))])
print(data_training.shape)
print(data_testing.shape)

data_training.head()

data_testing.head()

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))

data_training_array = scaler.fit_transform(data_training)
data_training_array

x_train = []
y_train = []

for i in range(100, data_training_array.shape[0]):
    x_train.append(data_training_array[i-100:i])
    y_train.append(data_training_array[i,0])

x_train,y_train = np.array(x_train), np.array(y_train)

"""#ML MODEL"""

import tensorflow as tf
from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional, TimeDistributed
from tensorflow.keras.layers import MaxPooling1D, Flatten
from tensorflow.keras.regularizers import L1,L2
from tensorflow.keras.metrics import RootMeanSquaredError

import tensorflow as tf
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, GRU, Dropout, Dense

model = tf.keras.Sequential()
model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(LSTM(units=128, activation='relu', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=128, activation='relu', return_sequences=True))
model.add(Dropout(0.3))
model.add(MaxPooling1D(2))

# GRU layer
model.add(Bidirectional(GRU(100, return_sequences=False)))
model.add(Dropout(0.5))

# Final layer
model.add(Dense(units=1, activation='linear'))

model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])
history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_train, y_train))

model.summary()

past_100_days = data_training.tail(100)

print(type(past_100_days))

final_df = pd.concat([past_100_days, data_testing], ignore_index=True)

final_df.head()

input_data = scaler.fit_transform(final_df)
input_data

input_data.shape

x_test = []
y_test = []

for i in range(100,input_data.shape[0]):
   x_test.append(input_data[i-100:i])
   y_test.append(input_data[i,0])

x_test,y_test = np.array(x_test), np.array(y_test)
print(x_test.shape)
print(y_test.shape)

#making Predictions

y_predicted = model.predict(x_test)

y_predicted.shape

y_test

y_predicted

scaler.scale_

scale_factor = 1/0.00164015
y_predicted = y_predicted * scale_factor
y_test = y_test * scale_factor

plt.figure(figsize=(8,3))
plt.plot(y_test, '#580F41', label = 'Original Price')
plt.plot(y_predicted, '#E50000', label = 'Predicted Price')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()
plt.show()

test = pd.DataFrame(y_test)
test.rename(columns={0: 'Test_value'}, inplace=True)
test

predicted = pd.DataFrame(y_predicted)
predicted.rename(columns={0: 'Predicted_value'}, inplace=True)
predicted

from sklearn.metrics import f1_score
import numpy as np
# Compute F1 score
f1 = f1_score(test, predicted)
print("F1 score:", f1)

from sklearn.metrics import f1_score
threshold_value = 0.5
true_labels_binary = (test > threshold_value).astype(int)
predictions_binary = (predicted > threshold_value).astype(int)
r_squared = f1_score(true_labels_binary, predictions_binary)
print("R-squared:", r_squared)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(test, predicted)

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(test, predicted)

# Calculate R-squared (R^2) score
r2 = r2_score(test, predicted)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared (R^2) Score:", r2)

import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# Assuming you have loaded your data into pandas DataFrame
# Replace df_test with the actual name of your DataFrame containing Test_value and Predicted_value
# Replace threshold_value with the appropriate threshold for your binary classification problem


threshold_value = 0.5  # Adjust this threshold according to your problem

# Convert probabilities to binary predictions based on the threshold
true_labels_binary = (test > threshold_value).astype(int)
predictions_binary = (predicted > threshold_value).astype(int)

# Calculate F1-score
f1 = f1_score(true_labels_binary, predictions_binary)

# Calculate accuracy
accuracy = accuracy_score(true_labels_binary, predictions_binary)

# Calculate ROCAUC
roc_auc = roc_auc_score(true_labels_binary, predicted)

print(f"F1-score: {f1}")
print(f"Accuracy: {accuracy}")
print(f"ROCAUC: {roc_auc}")