# -*- coding: utf-8 -*-
"""Stock Prediction Using ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPgo67ESDOD-Nb15zd8ojeCM2Nm_VyRB
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
from math import sqrt
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pandas_datareader import data as pdr
import yfinance as yf
import os

yf.pdr_override()
y_symbols = ['APOLLOHOSP.NS']
from datetime import datetime
startdate = datetime(2005,1,1)
enddate = datetime(2019,12,31)
data = pdr.get_data_yahoo(y_symbols, start=startdate, end=enddate)

data=data.reset_index()
data.head()

df = pd.DataFrame(data)

# Convert the 'Date' column to string
df['Date'] = df['Date'].astype(str)

# Split 'Date' column into 'Year', 'Month', and 'Day'
date_split = df['Date'].str.split('-', expand=True)
df['Year'], df['Month'], df['Day'] = date_split

# Convert 'Volume' column
df["Volume"] = df["Volume"] / 10000

# Print the modified DataFrame
df

df.head()

df.drop(df.columns[[0,3,6, 7,8,9]], axis=1, inplace=True)
df.head()

data_training = pd.DataFrame(df['Close'][0:int(len(data)*0.70)])
data_testing = pd.DataFrame(df['Close'][int(len(data)*0.70): int(len(data))])
print(data_training.shape)
print(data_testing.shape)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))

data_training_array = scaler.fit_transform(data_training)
data_training_array

x_train = []
y_train = []

for i in range(100, data_training_array.shape[0]):
    x_train.append(data_training_array[i-100:i])
    y_train.append(data_training_array[i,0])

x_train,y_train = np.array(x_train), np.array(y_train)

past_100_days = data_training.tail(100)

print(type(past_100_days))

final_df = pd.concat([past_100_days, data_testing], ignore_index=True)

final_df.head()

input_data = scaler.fit_transform(final_df)
input_data

input_data.shape

x_test = []
y_test = []

for i in range(100,input_data.shape[0]):
   x_test.append(input_data[i-100:i])
   y_test.append(input_data[i,0])

x_test,y_test = np.array(x_test), np.array(y_test)
print(x_test.shape)
print(y_test.shape)

y_test

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Bidirectional, GRU, Reshape
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming you have your data and target variables ready for training
# Let's assume your data is stored in X and target variable in y

# Initialize the classifier
classifier = Sequential()

# Add layers to the classifier
classifier.add(Dense(units=120, kernel_initializer='uniform', activation='relu'))
classifier.add(Dropout(0.5))
classifier.add(Dense(units=120, kernel_initializer='uniform', activation='relu'))
classifier.add(Dropout(0.5))

# Reshape the output into 3-dimensional shape for Bidirectional GRU
classifier.add(Reshape((-1, 120)))  # Adjust the shape according to your data

# Add the Bidirectional GRU layer
classifier.add(Bidirectional(GRU(100, return_sequences=False)))

# Add a Dropout layer to prevent overfitting
classifier.add(Dropout(0.5))

# Add the output layer with linear activation
classifier.add(Dense(units=1, kernel_initializer='uniform', activation='linear'))

# Compile the model
classifier.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae','accuracy'])  # Adjust optimizer and loss function as needed

# Fit the model to your data
classifier.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)  # Adjust epochs and batch size as needed

#making Predictions

y_predicted = classifier.predict(x_test)

y_predicted.shape

y_predicted

scaler.scale_

scale_factor = 1/0.00164015
y_predicted = y_predicted * scale_factor
y_test = y_test * scale_factor

import math

trainScore = classifier.evaluate(x_train, y_train, verbose=0)
trainMSE = trainScore[0]  # Assuming the MSE is the first element in the list
trainRMSE = math.sqrt(trainMSE)
print('Train Score: %.2f MSE (%.2f RMSE)' % (trainMSE, trainRMSE))

testScore = classifier.evaluate(x_test, y_test, verbose=0)
testMSE = testScore[0]  # Assuming the MSE is the first element in the list
testRMSE = math.sqrt(testMSE)
print('Test Score: %.2f MSE (%.2f RMSE)' % (testMSE, testRMSE))

import matplotlib.pyplot as plt
plt.figure(figsize=(8,3))
plt.plot(y_test, 'b', label = 'Original Price')
plt.plot(y_predicted, 'r', label = 'Predicted Price')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()
plt.show()

test = pd.DataFrame(y_test)
test.rename(columns={0: 'Test_value'}, inplace=True)
test

predicted = pd.DataFrame(y_predicted)
predicted.rename(columns={0: 'Predicted_value'}, inplace=True)
predicted

import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# Assuming you have loaded your data into pandas DataFrame
# Replace df_test with the actual name of your DataFrame containing Test_value and Predicted_value
# Replace threshold_value with the appropriate threshold for your binary classification problem


threshold_value = 0.5  # Adjust this threshold according to your problem

# Convert probabilities to binary predictions based on the threshold
true_labels_binary = (test > threshold_value).astype(int)
predictions_binary = (predicted > threshold_value).astype(int)

# Calculate F1-score
f1 = f1_score(true_labels_binary, predictions_binary)

# Calculate accuracy
accuracy = accuracy_score(true_labels_binary, predictions_binary)

# Calculate ROCAUC
roc_auc = roc_auc_score(true_labels_binary, predicted)

print(f"F1-score: {f1}")
print(f"Accuracy: {accuracy}")
print(f"ROCAUC: {roc_auc}")

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(test, predicted)

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(test, predicted)

# Calculate R-squared (R^2) score
r2 = r2_score(test, predicted)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared (R^2) Score:", r2)

from sklearn.metrics import r2_score
r_squared = r2_score(test, predicted)
print("R-squared:", r_squared)